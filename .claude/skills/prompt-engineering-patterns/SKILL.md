---
name: prompt-engineering-patterns
description: 掌握高级提示工程技术，以最大化生产环境中LLM的性能、可靠性和可控性。在优化提示、改进LLM输出或设计生产提示模板时使用。
---

# 提示工程模式

掌握高级提示工程技术，以最大化LLM的性能、可靠性和可控性。

## 何时使用此技能

- 为生产级LLM应用程序设计复杂提示
- 优化提示性能和一致性
- 实现结构化推理模式（思维链、思维树）
- 构建具有动态示例选择的小样本学习系统
- 创建具有变量插值功能可重用的提示模板
- 调试和优化产生不一致输出的提示
- 为专用AI助手实现系统提示

## 核心能力

### 1. 小样本学习
- 示例选择策略（语义相似性、多样性采样）
- 在上下文窗口约束下平衡示例数量
- 构建有效的输入输出对示范
- 从知识库动态检索示例
- 通过策略性示例选择处理边界情况

### 2. 思维链提示
- 逐步推理引导
- 零样本CoT："让我们一步步思考"
- 少样本CoT与推理轨迹
- 自一致性技术（采样多个推理路径）
- 验证和确认步骤

### 3. 提示优化
- 迭代优化工作流
- 提示变体的A/B测试
- 测量提示性能指标（准确性、一致性、延迟）
- 在保持质量的同时减少token使用
- 处理边界情况和失败模式

### 4. 模板系统
- 变量插值和格式化
- 条件提示部分
- 多轮对话模板
- 基于角色的提示组合
- 模块化提示组件

### 5. 系统提示设计
- 设置模型行为和约束
- 定义输出格式和结构
- 建立角色和专业能力
- 安全准则和内容策略
- 上下文设置和背景信息

## 快速开始

```python
from prompt_optimizer import PromptTemplate, FewShotSelector

# 定义结构化提示模板
template = PromptTemplate(
    system="你是一位专家级SQL开发者。生成高效、安全的SQL查询。",
    instruction="将以下自然语言查询转换为SQL：\n{query}",
    few_shot_examples=True,
    output_format="带有解释性注释的SQL代码块"
)

# 配置小样本学习
selector = FewShotSelector(
    examples_db="sql_examples.jsonl",
    selection_strategy="semantic_similarity",
    max_examples=3
)

# 生成优化提示
prompt = template.render(
    query="查找过去30天内注册的所有用户",
    examples=selector.select(query="用户注册日期筛选")
)
```

## 关键模式

### 渐进式披露
从简单提示开始，仅在需要时增加复杂性：

1. **级别1**：直接指令
   - "总结这篇文章"

2. **级别2**：添加约束
   - "用3个要点总结这篇文章，重点关注关键发现"

3. **级别3**：添加推理
   - "阅读这篇文章，识别主要发现，然后用3个要点总结"

4. **级别4**：添加示例
   - 包含2-3个带有输入输出对的示例总结

### 指令层次结构
```
[系统上下文] → [任务指令] → [示例] → [输入数据] → [输出格式]
```

### 错误恢复
构建能够优雅处理失败的提示：
- 包含备用指令
- 请求置信度分数
- 在不确定时要求替代解释
- 指定如何表示缺失信息

## 最佳实践

1. **具体明确**：模糊的提示会产生不一致的结果
2. **展示而非描述**：示例比描述更有效
3. **广泛测试**：在多样化、代表性的输入上进行评估
4. **快速迭代**：小的改动可能产生重大影响
5. **监控性能**：在生产环境中跟踪指标
6. **版本控制**：将提示作为代码进行适当的版本管理
7. **记录意图**：解释为什么提示要这样构建

## 常见陷阱

- **过度工程化**：在尝试简单提示之前就从复杂提示开始
- **示例污染**：使用与目标任务不匹配的示例
- **上下文溢出**：通过过多示例超出token限制
- **模糊指令**：留出多种解释空间
- **忽略边界情况**：不在异常或边界输入上测试

## 集成模式

### 与RAG系统集成
```python
# 将检索到的上下文与提示工程结合
prompt = f"""基于以下上下文：
{retrieved_context}

{few_shot_examples}

问题：{user_question}

仅根据上述上下文提供详细答案。如果上下文信息不足，请明确说明缺失的内容。"""
```

### 与验证集成
```python
# 添加自我验证步骤
prompt = f"""{main_task_prompt}

生成回答后，请验证其是否符合这些标准：
1. 直接回答问题
2. 仅使用所提供上下文中的信息
3. 引用具体来源
4. 承认任何不确定性

如果验证失败，请修改你的回答。"""
```

## 性能优化

### Token效率
- 移除冗余词语和短语
- 在首次定义后一致使用缩写
- 合并相似指令
- 将稳定内容移至系统提示

### 延迟降低
- 在不牺牲质量的前提下最小化提示长度
- 对长篇输出使用流式处理
- 缓存常用提示前缀
- 尽可能批量处理相似请求

## 资源

- **references/few-shot-learning.md**：深入探讨示例选择和构建
- **references/chain-of-thought.md**：高级推理引导技术
- **references/prompt-optimization.md**：系统化优化工作流
- **references/prompt-templates.md**：可重用模板模式
- **references/system-prompts.md**：系统级提示设计
- **assets/prompt-template-library.md**：经过实战检验的提示模板
- **assets/few-shot-examples.json**：精选示例数据集
- **scripts/optimize-prompt.py**：自动化提示优化工具

## 成功指标

为你的提示跟踪这些KPI：
- **准确性**：输出的正确性
- **一致性**：相似输入的可重现性
- **延迟**：响应时间（P50、P95、P99）
- **Token使用**：每次请求的平均token数
- **成功率**：有效输出的百分比
- **用户满意度**：评分和反馈

## 后续步骤

1. 查看提示模板库中的常见模式
2. 为你的特定用例尝试小样本学习
3. 实现提示版本管理和A/B测试
4. 设置自动化评估管道
5. 记录你的提示工程决策和经验教训